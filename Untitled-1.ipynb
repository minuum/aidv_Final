{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader, TextLoader\n",
    "from streaming import StreamHandler\n",
    "import utils\n",
    "\n",
    "st.title(\"당뇨 환자들을 위한 챗봇\")\n",
    "\n",
    "# openai key input gui. 없으면 여기서 멈춤 있으면 계속 진행\n",
    "model_name = utils.configure_openai()\n",
    "\n",
    "\n",
    "# qa_chain 최초로 한번 정의하고 session_state에 저장해둠.  os.environ['OPENAI_API_KEY'] 없는 상태로 Chroma 객체 생성하면 에러남\n",
    "if \"qa_chain\" not in st.session_state:\n",
    "    # 각 확장자 별로 문서 로더 정의\n",
    "    documents = []\n",
    "\n",
    "    loaders = {\n",
    "        'pdf': {'loader':PyMuPDFLoader, 'kwargs': {}},\n",
    "        'txt': {'loader':TextLoader, 'kwargs': {'autodetect_encoding': True}}\n",
    "    }\n",
    "    for file_type, value in loaders.items():\n",
    "        loader = value['loader']\n",
    "        loader_kwargs = value['kwargs']\n",
    "\n",
    "        loader = DirectoryLoader(path=f\"data/{file_type}\", glob=f\"**/*.{file_type}\",loader_cls=loader, loader_kwargs=loader_kwargs)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "    # 간단한 키워드 기반 문서 검색기 정의\n",
    "    embedding = OpenAIEmbeddings()\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding)\n",
    "\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=0, streaming=True)\n",
    "\n",
    "    st.session_state[\"qa_chain\"] = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "\n",
    "#chat gui\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
    "\n",
    "for msg in st.session_state[\"messages\"]:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "user_query = st.chat_input(placeholder=\"당뇨 관련 질문하세요!\")\n",
    "\n",
    "if user_query:\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "        st.write(user_query)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st_cb = StreamHandler(st.empty())\n",
    "        result = st.session_state[\"qa_chain\"].invoke(\n",
    "            {\"query\":user_query},\n",
    "            {\"callbacks\": [st_cb]}\n",
    "        )\n",
    "        response = result[\"result\"]\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        # to show references\n",
    "        for idx, doc in enumerate(result['source_documents'],1):\n",
    "            filename = os.path.basename(doc.metadata['source'])\n",
    "            _, ext = os.path.splitext(filename)\n",
    "        \n",
    "            if ext == '.txt':\n",
    "                ref_title = f\":blue[Reference {idx}: *{filename}*]\"\n",
    "            elif ext == '.pdf':\n",
    "                page_num = doc.metadata['page']\n",
    "                ref_title = f\":blue[Reference {idx}: *{filename} - page.{page_num}*]\"\n",
    "\n",
    "            with st.popover(ref_title):\n",
    "                st.caption(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
